<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>咸鱼有点闲</title>
  
  <subtitle>Dick</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://wxzhongwang.github.io/"/>
  <updated>2019-01-08T06:36:16.053Z</updated>
  <id>https://wxzhongwang.github.io/</id>
  
  <author>
    <name>Dick Zhong</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Redis和Memcached比较</title>
    <link href="https://wxzhongwang.github.io/2019/01/08/Redis%E5%92%8CMemcached%E6%AF%94%E8%BE%83/"/>
    <id>https://wxzhongwang.github.io/2019/01/08/Redis和Memcached比较/</id>
    <published>2019-01-08T06:33:59.000Z</published>
    <updated>2019-01-08T06:36:16.053Z</updated>
    
    <content type="html"><![CDATA[<p>Redis和Memcache都是将数据存放在内存中，都是内存数据库。本文介绍两者的区别。</p><h1 id="Redis和Memcached比较"><a href="#Redis和Memcached比较" class="headerlink" title="Redis和Memcached比较"></a>Redis和Memcached比较</h1><ul><li><p>Memcached是多线程，而Redis使用单线程.</p></li><li><p>Memcached使用预分配的内存池的方式，Redis使用现场申请内存的方式来存储数据，并且可以配置虚拟内存。</p></li><li><p>Redis可以实现持久化，主从复制，实现故障恢复。</p></li><li><p>Memcached只是简单的key与value,但是Redis支持数据类型比较多。</p></li></ul><p>Redis的存储分为内存存储、磁盘存储 .从这一点，也说明了Redis与Memcached是有区别的。Redis 与Memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改 操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步。</p><p>Redis有两种存储方式(默认:snapshot)</p><ol><li>snapshot<blockquote><p>实现方法是定时将内存的快照(snapshot)持久化到硬盘，<br>这种方法缺点是持久化之后如果出现crash则会丢失一段数据。<br>因此在完美主义者的推动下作者增加了aof方式。</p></blockquote></li></ol><ol start="2"><li>aof<blockquote><p>即append only mode，在写入内存数据的同时将操作命令保存到日志文件，在一个并发更改上万的系统中，命令日志是一个非常庞大的数据，管理维护成本非常高，恢复重建时间会非常长，这样导致失去aof高可用性本意。另外更重要的是Redis是一个内存数据结构模型，所有的优势都是建立在对内存复杂数据结构高效的原子操作</p></blockquote></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Redis和Memcache都是将数据存放在内存中，都是内存数据库。本文介绍两者的区别。&lt;/p&gt;
&lt;h1 id=&quot;Redis和Memcached比较&quot;&gt;&lt;a href=&quot;#Redis和Memcached比较&quot; class=&quot;headerlink&quot; title=&quot;Redis和
      
    
    </summary>
    
      <category term="Redis" scheme="https://wxzhongwang.github.io/categories/Redis/"/>
    
    
      <category term="Redis" scheme="https://wxzhongwang.github.io/tags/Redis/"/>
    
      <category term="NOSQL" scheme="https://wxzhongwang.github.io/tags/NOSQL/"/>
    
  </entry>
  
  <entry>
    <title>Redis简介</title>
    <link href="https://wxzhongwang.github.io/2019/01/08/Redis%E7%AE%80%E4%BB%8B/"/>
    <id>https://wxzhongwang.github.io/2019/01/08/Redis简介/</id>
    <published>2019-01-08T06:31:13.000Z</published>
    <updated>2019-01-08T06:32:04.017Z</updated>
    
    <content type="html"><![CDATA[<p>Redis是一个开源的，使用C语言编写，面向“键/值”对类型数据的分布式NoSQL数据库系统，特点是高性能，持久存储，适应高并发的应用场景。Redis纯粹为应用而产生，它是一个高性能的key-value数据库,并且提供了多种语言的API，性能测试结果表示SET操作每秒钟可达110000次，GET操作每秒81000次（当然不同的服务器配置性能不同）。</p><h1 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h1><p>Redis是一个开源的，使用C语言编写，面向“键/值”对类型数据的分布式NoSQL数据库系统，特点是高性能，持久存储，适应高并发的应用场景。Redis纯粹为应用而产生，它是一个高性能的key-value数据库,并且提供了多种语言的API，性能测试结果表示SET操作每秒钟可达110000次，GET操作每秒81000次（当然不同的服务器配置性能不同）。</p><p>Redis目前提供五种数据类型：</p><ul><li>string(字符串),</li><li>list（链表）, </li><li>Hash（哈希）,</li><li>set（集合）,</li><li>zset(sorted set)  （有序集合）</li></ul><p>Redis开发维护很活跃，虽然它是一个Key-Value数据库存储系统，但它本身支持MQ功能，所以完全可以当做一个轻量级的队列服务来使用。</p><p>Redis可以做消息队列？</p><blockquote><p>首先，redis设计用来做缓存的，但是由于它自身的某种特性使得它可以用来做消息队列，它有几个阻塞式的API可以使用，正是这些阻塞式的API让其有能力做消息队列；另外，做消息队列的其他特性例如FIFO（先入先出）也很容易实现，只需要一个list对象从头取数据，从尾部塞数据即可；redis能做消息队列还得益于其list对象blpop brpop接口以及Pub/Sub（发布/订阅）的某些接口，它们都是阻塞版的，所以可以用来做消息队列。</p></blockquote><p>对于RabbitMQ和Redis的入队和出队操作，各执行100万次，每10万次记录一次执行时间。测试数据分为128Bytes、512Bytes、1K和10K四个不同大小的数据。<br>实验表明：</p><blockquote><p>入队时，当数据比较小时Redis的性能要高于RabbitMQ，而如果数据大小超过了10K，Redis则慢的无法忍<br>受；出队时，无论数据大小，Redis都表现出非常好的性能，而RabbitMQ的出队性能则远低于Redis。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Redis是一个开源的，使用C语言编写，面向“键/值”对类型数据的分布式NoSQL数据库系统，特点是高性能，持久存储，适应高并发的应用场景。Redis纯粹为应用而产生，它是一个高性能的key-value数据库,并且提供了多种语言的API，性能测试结果表示SET操作每秒钟可达
      
    
    </summary>
    
      <category term="Redis" scheme="https://wxzhongwang.github.io/categories/Redis/"/>
    
    
      <category term="Redis" scheme="https://wxzhongwang.github.io/tags/Redis/"/>
    
      <category term="消息队列" scheme="https://wxzhongwang.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>sass sass-loader</title>
    <link href="https://wxzhongwang.github.io/2019/01/08/windows%E4%B8%8B%E5%AE%89%E8%A3%85node-sass%E5%92%8Csass-loader%E5%A4%B1%E8%B4%A5/"/>
    <id>https://wxzhongwang.github.io/2019/01/08/windows下安装node-sass和sass-loader失败/</id>
    <published>2019-01-08T06:18:02.000Z</published>
    <updated>2019-01-09T02:00:59.017Z</updated>
    
    <content type="html"><![CDATA[<p>window下无法安装sass sass-loader</p><h2 id="node-sass安装失败的原因是网络限制导致无法下载-node文件"><a href="#node-sass安装失败的原因是网络限制导致无法下载-node文件" class="headerlink" title="node-sass安装失败的原因是网络限制导致无法下载.node文件"></a>node-sass安装失败的原因是网络限制导致无法下载.node文件</h2><blockquote><p>推荐方法：使用淘宝镜像</p></blockquote><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm set <span class="attr">sass_binary_site=</span>https://npm.taobao.org/mirrors/<span class="keyword">node</span><span class="title">-sass</span>/</span><br></pre></td></tr></table></figure><p>or</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm install -g cnpm --<span class="attr">registry=</span>https://registry.npm.taobao.org</span><br><span class="line">cnpm install <span class="keyword">node</span><span class="title">-sass</span> sass-loader -S</span><br></pre></td></tr></table></figure><p>其他翻墙、手动导入文件的方式不推荐。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;window下无法安装sass sass-loader&lt;/p&gt;
&lt;h2 id=&quot;node-sass安装失败的原因是网络限制导致无法下载-node文件&quot;&gt;&lt;a href=&quot;#node-sass安装失败的原因是网络限制导致无法下载-node文件&quot; class=&quot;headerli
      
    
    </summary>
    
      <category term="前端" scheme="https://wxzhongwang.github.io/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
      <category term="Web" scheme="https://wxzhongwang.github.io/tags/Web/"/>
    
  </entry>
  
  <entry>
    <title>Linux常用命令</title>
    <link href="https://wxzhongwang.github.io/2019/01/08/Linux%20%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <id>https://wxzhongwang.github.io/2019/01/08/Linux 常用命令/</id>
    <published>2019-01-08T06:18:02.000Z</published>
    <updated>2019-01-09T01:59:11.725Z</updated>
    
    <content type="html"><![CDATA[<p>Linux常用命令</p><p>#Linux 常用命令</p><h2 id="cd"><a href="#cd" class="headerlink" title="cd"></a>cd</h2><ul><li>==cd /== 进入主目录</li><li>==cd ~== 进入Home目录</li><li>==cd -== 进入上一次工作中路径</li></ul><h2 id="ls"><a href="#ls" class="headerlink" title="ls"></a>ls</h2><ul><li>==ls -a== 列出所有</li><li>==ls -r== 反序排列</li><li>==ls -t== 以文件修改时间排列</li><li>==ls -l== 将文件名,文件所有者，文件大小信息详细信息列出来</li></ul><h2 id="pwd"><a href="#pwd" class="headerlink" title="pwd"></a>pwd</h2><ul><li>==pwd== 展示当前工作目录路径</li></ul><h2 id="mkdir"><a href="#mkdir" class="headerlink" title="mkdir"></a>mkdir</h2><p>创建文件夹<br>可用选项：</p><ul><li>==mkdir -m==: 对新建目录设置存取权限,也可以用chmod命令设置;</li><li>==mkdir -p==: 可以是一个路径名称。此时若路径中的某些目录尚不存在,加上此选项后,系统将自动建立那 些尚不在的目录,即一次可以建立多个目录;</li></ul><h2 id="rm"><a href="#rm" class="headerlink" title="rm"></a>rm</h2><p>删除文件，删除一个目录中的一个或多个文件或目录，如果没有使用- r选项，则rm不会删除目录</p><h2 id="rmdir"><a href="#rmdir" class="headerlink" title="rmdir"></a>rmdir</h2><p>从一个目录中删除一个或多个子目录项，删除某目录时也必须具有对其父目录的写权限。</p><h2 id="mv"><a href="#mv" class="headerlink" title="mv"></a>mv</h2><p>移动文件或修改文件名，根据第二参数类型（如目录，则移动文件；如为文件则重命令该文件）。</p><h2 id="cp"><a href="#cp" class="headerlink" title="cp"></a>cp</h2><p>将源文件复制至目标文件，或将多个源文件复制至目标目录。</p><h2 id="free"><a href="#free" class="headerlink" title="free"></a>free</h2><p>显示系统内存使用情况，包括物理内存、交互区内存(swap)和内核缓冲区内存</p><ul><li>-b 以Byte显示内存使用情况</li><li>-k 以kb为单位显示内存使用情况</li><li>-m 以mb为单位显示内存使用情况</li><li>-g 以gb为单位显示内存使用情况</li><li>-s &lt;间隔秒数&gt; 持续显示内存</li><li>-t 显示内存使用总合</li></ul><h2 id="cat"><a href="#cat" class="headerlink" title="cat"></a>cat</h2><p>  cat主要有三大功能：</p><ul><li>一次显示整个文件:cat filename</li><li>从键盘创建一个文件:cat &gt; filename 只能创建新文件,不能编辑已有文件.</li><li>将几个文件合并为一个文件:cat file1 file2 &gt; file</li></ul><ol><li>-b对非空输出行号</li><li>-n输出所有行号</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Linux常用命令&lt;/p&gt;
&lt;p&gt;#Linux 常用命令&lt;/p&gt;
&lt;h2 id=&quot;cd&quot;&gt;&lt;a href=&quot;#cd&quot; class=&quot;headerlink&quot; title=&quot;cd&quot;&gt;&lt;/a&gt;cd&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;==cd /== 进入主目录&lt;/li&gt;
&lt;li&gt;==cd
      
    
    </summary>
    
      <category term="Linux" scheme="https://wxzhongwang.github.io/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://wxzhongwang.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Mock.js</title>
    <link href="https://wxzhongwang.github.io/2019/01/08/Mockjs/"/>
    <id>https://wxzhongwang.github.io/2019/01/08/Mockjs/</id>
    <published>2019-01-08T06:18:02.000Z</published>
    <updated>2019-01-09T01:59:54.941Z</updated>
    
    <content type="html"><![CDATA[<p>目前的大部分公司的项目都是采用的前后端分离, 后端接口的开发和前端人员是同时进行的. 那么这个时候就会存在一个问题, 在页面需要使用大量数据进行渲染生成前, 后端开发人员的接口也许并没有写完, 作为前端的我们也就没有办法获取数据. 所以 前端工程师就需要自己按照接口文档模拟后端人员提供的数据, 以此进行页面的开发.<br>这个时候, Mock.js的作用就体现出来了, 在数据量较大的情况下, 我们不用一个一个的编写数据, 只需要根据接口文档将数据的格式填入,Mock.js就能够自动的按需生成大量的模拟数据. 且Mock.js提供了大量的数据类型, 包括文本, 数字, 布尔值, 日期, 邮箱, 链接, 图片, 颜色等.</p><h1 id="Mock-js"><a href="#Mock-js" class="headerlink" title="Mock.js"></a>Mock.js</h1><h2 id="Mockjs是什么"><a href="#Mockjs是什么" class="headerlink" title="Mockjs是什么?"></a>Mockjs是什么?</h2><p>目前的大部分公司的项目都是采用的前后端分离, 后端接口的开发和前端人员是同时进行的. 那么这个时候就会存在一个问题, 在页面需要使用大量数据进行渲染生成前, 后端开发人员的接口也许并没有写完, 作为前端的我们也就没有办法获取数据. 所以 前端工程师就需要自己按照接口文档模拟后端人员提供的数据, 以此进行页面的开发.<br>这个时候, Mock.js的作用就体现出来了, 在数据量较大的情况下, 我们不用一个一个的编写数据, 只需要根据接口文档将数据的格式填入,Mock.js就能够自动的按需生成大量的模拟数据. 且Mock.js提供了大量的数据类型, 包括文本, 数字, 布尔值, 日期, 邮箱, 链接, 图片, 颜色等.</p><h2 id="安装Mockjs"><a href="#安装Mockjs" class="headerlink" title="安装Mockjs"></a>安装Mockjs</h2><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npm <span class="keyword">install</span> mockjs -S </span><br><span class="line"><span class="keyword">or</span> </span><br><span class="line">npm <span class="keyword">install</span> mockjs -D</span><br></pre></td></tr></table></figure><h2 id="引用Mockjs"><a href="#引用Mockjs" class="headerlink" title="引用Mockjs"></a>引用Mockjs</h2><p>Mock.js暴露了一个全局的Mock对象, 我们只需要将Mock对象引入到文件中, 调用Mock对象的方法即可</p><ul><li>CommonJS的引入方式</li></ul><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//CommonJS引入</span></span><br><span class="line"><span class="keyword">let</span> Mock = require(<span class="symbol">'mockjs</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment">//调用Mock.mock()方法模拟数据</span></span><br><span class="line"><span class="keyword">let</span> data = Mock.mock(&#123;</span><br><span class="line"><span class="symbol">'list</span>|<span class="number">1</span>-<span class="number">10</span>': [&#123;</span><br><span class="line">  <span class="symbol">'id</span>|+<span class="number">1</span>': <span class="number">1</span></span><br><span class="line">&#125;]</span><br><span class="line">&#125;);</span><br><span class="line">console.log(data);</span><br></pre></td></tr></table></figure><ul><li>ES6的引入方式</li></ul><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//ES6的引入方式</span></span><br><span class="line"><span class="keyword">import</span> Mock <span class="keyword">from</span> <span class="string">'mockjs'</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">let</span> data = Mock.mock(&#123;</span><br><span class="line"><span class="string">'list|1-10'</span>: [&#123;</span><br><span class="line">  <span class="string">'id|+1'</span>: <span class="number">1</span></span><br><span class="line">&#125;]</span><br><span class="line">&#125;);</span><br><span class="line"><span class="built_in">console</span>.log(data);</span><br></pre></td></tr></table></figure><h2 id="简单用法"><a href="#简单用法" class="headerlink" title="简单用法"></a>简单用法</h2><p>Mock对象提供了4个方法, 分别是</p><ul><li>Mock.mock()</li><li>Mock.setup()</li><li>Mock.valid</li><li>Mock.toJSONSchema()</li></ul><p>以及一个工具库 Mock.Random. 其中我们经常使用到的就是Mock.mock()和Mock.Random.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;目前的大部分公司的项目都是采用的前后端分离, 后端接口的开发和前端人员是同时进行的. 那么这个时候就会存在一个问题, 在页面需要使用大量数据进行渲染生成前, 后端开发人员的接口也许并没有写完, 作为前端的我们也就没有办法获取数据. 所以 前端工程师就需要自己按照接口文档模拟
      
    
    </summary>
    
      <category term="前端" scheme="https://wxzhongwang.github.io/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
      <category term="Web" scheme="https://wxzhongwang.github.io/tags/Web/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop概念</title>
    <link href="https://wxzhongwang.github.io/2019/01/08/Hadoop/"/>
    <id>https://wxzhongwang.github.io/2019/01/08/Hadoop/</id>
    <published>2019-01-08T06:18:02.000Z</published>
    <updated>2019-01-09T01:59:09.755Z</updated>
    
    <content type="html"><![CDATA[<p>Hadoop是一个开源的框架，可编写和运行分布式应用处理大规模数据，是专为离线和大规模数据分析而设计的，并不适合那种对几个记录随机读写的在线事务处理模式。</p><h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><ul><li>Hadoop是一个开源的框架，可编写和运行分布式应用处理大规模数据，是专为离线和大规模数据分析而设计的，并不适合那种对几个记录随机读写的在线事务处理模式。 ==不是为了大数据而大数据==</li><li>Hadoop 是以一种可靠、高效、可伸缩的方式进行处理的。Hadoop 是可靠的，因为它假设计算元素和存储会失败，因此它维护多个工作数据副本，确保能够针对失败的节点重新分布处理。Hadoop 是高效的，因为它以并行的方式工作，通过并行处理加快处理速度。Hadoop 还是可伸缩的，能够处理 PB 级数据。<h2 id="核心"><a href="#核心" class="headerlink" title="核心"></a>核心</h2>Hadoop的核心就是==HDFS==和==MapReduce===，Hadoop旗下有很多经典子项目，比如HBase、Hive等，这些都是基于HDFS和MapReduce发展出来的。要想了解Hadoop，就必须知道HDFS和MapReduce是什么。<h3 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h3>Hadoop Distributed File System，Hadoop 分布式文件系统<br>高度容错性的系统，适合部署在廉价的机器上，HDFS能提供高吞吐量的数据访问，适合那些有着超大数据集（large data set）的应用程序。<h3 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h3>Mapreduce是一个计算框架，一个处理分布式海量数据的软件框架及计算集群。</li></ul><h2 id="用处"><a href="#用处" class="headerlink" title="用处"></a>用处</h2><ul><li>搜索引擎 - 设计Hadoop的初衷，为了针对大规模的网页快速建立索引）</li><li>大数据存储 - 利用Hadoop的分布式存储能力，例如数据备份、数据仓库等。</li><li>大数据处理 - 利用Hadoop的分布式处理能力，例如数据挖掘、数据分析等。</li><li>科学研究 - Hadoop是一种分布式的开源框架，对于分布式计算有很大程度地参考价值。</li></ul><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>==高可靠性==<br>Hadoop按位存储和处理数据的能力值得信赖。</p><p>==高扩展性==<br>Hadoop是在可用的计算机集簇间分配数据并完成计算任务的，这些集簇可以方便地扩展到数以千计的节点中。</p><p>==高效性==<br>Hadoop能够在节点之间动态地移动数据，并保证各个节点的动态平衡，因此处理速度非常快。</p><p>==高容错性==<br>Hadoop能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配。</p><p>==低成本==<br>与一体机、商用数据仓库以及QlikView、Yonghong Z-Suite等数据集市相比，hadoop是开源的，项目的软件成本因此会大大降低。</p><blockquote><p>Hadoop设计对硬件需求比较低，只须运行在低廉的商用硬件集群上，而无需昂贵的高可用性机器上。廉价的商用机也就意味着大型集群中出现节点故障情况的概率非常高。这就要求设计HDFS时要充分考虑数据的可靠性，安全性及高可用性。</p></blockquote><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>==不适合低延迟数据访问==</p><blockquote><p>如果要处理一些用户要求时间比较短的低延迟应用请求，则HDFS不适合。HDFS是为了处理大型数据集分析任务的，主要是为达到高的数据吞吐量而设计的，这就可能要求以高延迟作为代价。</p></blockquote><blockquote><p>改进策略：对于那些有低延时要求的应用程序，HBase是一个更好的选择。通过上层数据管理项目来尽可能地弥补这个不足。在性能上有了很大的提升，它的口号就是goes real time。使用缓存或多master设计可以降低client的数据请求压力，以减少延时。还有就是对HDFS系统内部的修改，这就得权衡大吞吐量与低延时了，HDFS不是万能的银弹。</p></blockquote><p>==无法高效存储大量小文件==</p><blockquote><p>因为Namenode把文件系统的元数据放置在内存中，所以文件系统所能容纳的文件数目是由Namenode的内存大小来决定。一般来说，每一个文件、文件夹和Block需要占据150字节左右的空间，所以，如果你有100万个文件，每一个占据一个Block，你就至少需要300MB内存。当前来说，数百万的文件还是可行的，当扩展到数十亿时，对于当前的硬件水平来说就没法实现了。还有一个问题就是，因为Maptask的数量是由splits来决定的，所以用MR处理大量的小文件时，就会产生过多的Maptask，线程管理开销将会增加作业时间。举个例子，处理10000M的文件，若每个split为1M，那就会有10000个Maptasks，会有很大的线程开销；若每个split为100M，则只有100个Maptasks，每个Maptask将会有更多的事情做，而线程的管理开销将减小很多。</p></blockquote><p>==不支持多用户写入及任意修改文件==  </p><blockquote><p>在HDFS的一个文件中只有一个写入者，而且写操作只能在文件末尾完成，即只能执行追加操作。目前HDFS还不支持多个用户对同一文件的写操作，以及在文件任意位置进行修改。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Hadoop是一个开源的框架，可编写和运行分布式应用处理大规模数据，是专为离线和大规模数据分析而设计的，并不适合那种对几个记录随机读写的在线事务处理模式。&lt;/p&gt;
&lt;h1 id=&quot;Hadoop&quot;&gt;&lt;a href=&quot;#Hadoop&quot; class=&quot;headerlink&quot; ti
      
    
    </summary>
    
      <category term="大数据" scheme="https://wxzhongwang.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://wxzhongwang.github.io/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>HttpStatusCode</title>
    <link href="https://wxzhongwang.github.io/2019/01/08/HttpStatusCode/"/>
    <id>https://wxzhongwang.github.io/2019/01/08/HttpStatusCode/</id>
    <published>2019-01-08T06:18:02.000Z</published>
    <updated>2019-01-09T01:57:21.644Z</updated>
    
    <content type="html"><![CDATA[<h1 id="HttpStatusCode"><a href="#HttpStatusCode" class="headerlink" title="HttpStatusCode"></a>HttpStatusCode</h1><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"> <span class="comment">/*</span></span><br><span class="line"><span class="comment">    1xx：相关信息</span></span><br><span class="line"><span class="comment">    2xx：操作成功</span></span><br><span class="line"><span class="comment">    3xx：重定向</span></span><br><span class="line"><span class="comment">    4xx：客户端错误</span></span><br><span class="line"><span class="comment">    5xx：服务器错误</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure><table><thead><tr><th style="text-align:center">字段</th><th style="text-align:left">状态码</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:center">Continue</td><td style="text-align:left">100</td><td style="text-align:left">指示客户端可能继续其请求。</td></tr><tr><td style="text-align:center">SwitchingProtocols</td><td style="text-align:left">100</td><td style="text-align:left">指示正在更改协议版本或协议。</td></tr><tr><td style="text-align:center">OK</td><td style="text-align:left">200</td><td style="text-align:left">指示请求成功，且请求的信息包含在响应中。</td></tr><tr><td style="text-align:center">Created</td><td style="text-align:left">201</td><td style="text-align:left">指示请求导致在响应被发送前创建新资源。</td></tr><tr><td style="text-align:center">Accepted</td><td style="text-align:left">202</td><td style="text-align:left">指示请求已被接受做进一步处理。</td></tr><tr><td style="text-align:center">NonAuthoritativeInformation</td><td style="text-align:left">202</td><td style="text-align:left">指示返回的元信息来自缓存副本而不是原始服务器，因此可能不正确。</td></tr><tr><td style="text-align:center">NoContent</td><td style="text-align:left">204</td><td style="text-align:left">指示请求成功，指示已成功处理请求并且响应已被设定为无内容。</td></tr><tr><td style="text-align:center">ResetContent</td><td style="text-align:left">205</td><td style="text-align:left">指示客户端应重置（或重新加载）当前资源。</td></tr><tr><td style="text-align:center">PartialContent</td><td style="text-align:left">206</td><td style="text-align:left">指示响应是包括字节范围的 GET 请求所请求的部分响应。</td></tr><tr><td style="text-align:center">MultipleChoices</td><td style="text-align:left">300</td><td style="text-align:left">指示请求的信息有多种表示形式，默认操作是将此状态视为重定向，并遵循与此响应关联的 Location 头的内容。</td></tr><tr><td style="text-align:center">Ambiguous</td><td style="text-align:left">300</td><td style="text-align:left">指示请求的信息有多种表示形式。默认操作是将此状态视为重定向，并遵循与此响应关联的 Location 头的内容。</td></tr><tr><td style="text-align:center">MovedPermanently</td><td style="text-align:left">301</td><td style="text-align:left">指示请求的信息已移到 Location 头中指定的 URI 处。接收到此状态时的默认操作为遵循与响应关联的 Location 头。</td></tr><tr><td style="text-align:center">Moved</td><td style="text-align:left">301</td><td style="text-align:left">指示请求的信息已移到 Location 头中指定的 URI 处。接收到此状态时的默认操作为遵循与响应关联的 Location 头。原始请求方法为 POST 时，重定向的请求将使用 GET 方法。</td></tr><tr><td style="text-align:center">Found</td><td style="text-align:left">302</td><td style="text-align:left">指示请求的信息位于 Location 头中指定的 URI 处。接收到此状态时的默认操作为遵循与响应关联的 Location 头。原始请求方法为 POST 时，重定向的请求将使用 GET 方法。</td></tr><tr><td style="text-align:center">Redirect</td><td style="text-align:left">302</td><td style="text-align:left">指示请求的信息位于 Location 头中指定的 URI 处。接收到此状态时的默认操作为遵循与响应关联的 Location 头。原始请求方法为 POST 时，重定向的请求将使用 GET 方法。</td></tr><tr><td style="text-align:center">SeeOther</td><td style="text-align:left">303</td><td style="text-align:left">作为 POST 的结果，SeeOther 将客户端自动重定向到 Location 头中指定的 URI。用 GET 生成对 Location 头所指定的资源的请求。</td></tr><tr><td style="text-align:center">RedirectMethod</td><td style="text-align:left">303</td><td style="text-align:left">作为 POST 的结果，RedirectMethod 将客户端自动重定向到 Location 头中指定的 URI。用 GET 生成对 Location 头所指定的资源的请求。</td></tr><tr><td style="text-align:center">NotModified</td><td style="text-align:left">304</td><td style="text-align:left">指示客户端的缓存副本是最新的。未传输此资源的内容。</td></tr><tr><td style="text-align:center">UseProxy</td><td style="text-align:left">305</td><td style="text-align:left">指示请求应使用位于 Location 头中指定的 URI 的代理服务器。</td></tr><tr><td style="text-align:center">Unused</td><td style="text-align:left">306</td><td style="text-align:left">是未完全指定的 HTTP/1.1 规范的建议扩展。</td></tr><tr><td style="text-align:center">TemporaryRedirect</td><td style="text-align:left">307</td><td style="text-align:left">指示请求信息位于 Location 头中指定的 URI 处。接收到此状态时的默认操作为遵循与响应关联的 Location 头。原始请求方法为 POST 时，重定向的请求还将使用 POST 方法。</td></tr><tr><td style="text-align:center">RedirectKeepVerb</td><td style="text-align:left">307</td><td style="text-align:left">指示请求信息位于 Location 头中指定的 URI 处。接收到此状态时的默认操作为遵循与响应关联的 Location 头。原始请求方法为 POST 时，重定向的请求还将使用 POST 方法。</td></tr><tr><td style="text-align:center">BadRequest</td><td style="text-align:left">400</td><td style="text-align:left">指示服务器未能识别请求。如果没有其他适用的错误，或者如果不知道准确的错误或错误没有自己的错误代码，则发送 BadRequest。</td></tr><tr><td style="text-align:center">Unauthorized</td><td style="text-align:left">401</td><td style="text-align:left">指示请求的资源要求身份验证。WWW-Authenticate头包含如何执行身份验证的详细信息。</td></tr><tr><td style="text-align:center">PaymentRequired</td><td style="text-align:left">402</td><td style="text-align:left">保留 PaymentRequired 以供将来使用。</td></tr><tr><td style="text-align:center">Forbidden</td><td style="text-align:left">403</td><td style="text-align:left">指示服务器拒绝满足请求。</td></tr><tr><td style="text-align:center">NotFound</td><td style="text-align:left">404</td><td style="text-align:left">指示请求的资源不在服务器上。</td></tr><tr><td style="text-align:center">MethodNotAllowed</td><td style="text-align:left">405</td><td style="text-align:left">指示请求的资源上不允许请求方法（POST 或 GET）。</td></tr><tr><td style="text-align:center">NotAcceptable</td><td style="text-align:left">406</td><td style="text-align:left">指示客户端已用 Accept 头指示将不接受资源的任何可用表示形式。</td></tr><tr><td style="text-align:center">ProxyAuthenticationRequired</td><td style="text-align:left">407</td><td style="text-align:left">指示请求的代理要求身份验证。Proxy-authenticate 头包含如何执行身份验证的详细信息。</td></tr><tr><td style="text-align:center">RequestTimeout</td><td style="text-align:left">408</td><td style="text-align:left">指示客户端没有在服务器期望请求的时间内发送请求。</td></tr><tr><td style="text-align:center">Conflict</td><td style="text-align:left">409</td><td style="text-align:left">指示由于服务器上的冲突而未能执行请求。</td></tr><tr><td style="text-align:center">Gone</td><td style="text-align:left">410</td><td style="text-align:left">指示请求的资源不再可用。</td></tr><tr><td style="text-align:center">LengthRequired</td><td style="text-align:left">411</td><td style="text-align:left">指示缺少必需的 Content-length 头。</td></tr><tr><td style="text-align:center">PreconditionFailed</td><td style="text-align:left">412</td><td style="text-align:left">指示为此请求设置的条件失败，且无法执行此请求。条件是用条件请求标头（如 If-Match、If-None-Match 或 If-Unmodified-Since）设置的。</td></tr><tr><td style="text-align:center">RequestEntityTooLarge</td><td style="text-align:left">413</td><td style="text-align:left">指示请求太大，服务器无法处理。</td></tr><tr><td style="text-align:center">RequestUriTooLong</td><td style="text-align:left">414</td><td style="text-align:left">指示 URI 太长。</td></tr><tr><td style="text-align:center">UnsupportedMediaType</td><td style="text-align:left">415</td><td style="text-align:left">指示请求是不支持的类型。</td></tr><tr><td style="text-align:center">RequestedRangeNotSatisfiable</td><td style="text-align:left">416</td><td style="text-align:left">RequestedRangeNotSatisfiable指示无法返回从资源请求的数据范围，因为范围的开头在资源的开头之前，或因为范围的结尾在资源的结尾之后。</td></tr><tr><td style="text-align:center">ExpectationFailed</td><td style="text-align:left">417</td><td style="text-align:left">指示服务器未能符合 Expect 头中给定的预期值。</td></tr><tr><td style="text-align:center">UpgradeRequired</td><td style="text-align:left">426</td><td style="text-align:left">客户端应当切换到TLS/1.0</td></tr><tr><td style="text-align:center">InternalServerError</td><td style="text-align:left">500</td><td style="text-align:left">指示服务器上发生了一般错误。</td></tr><tr><td style="text-align:center">NotImplemented</td><td style="text-align:left">501</td><td style="text-align:left">指示服务器不支持请求的函数。</td></tr><tr><td style="text-align:center">BadGateway</td><td style="text-align:left">502</td><td style="text-align:left">指示中间代理服务器从另一代理或原始服务器接收到错误响应。</td></tr><tr><td style="text-align:center">ServiceUnavailable</td><td style="text-align:left">503</td><td style="text-align:left">指示服务器暂时不可用，通常是由于过多加载或维护。</td></tr><tr><td style="text-align:center">GatewayTimeout</td><td style="text-align:left">504</td><td style="text-align:left">指示中间代理服务器在等待来自另一个代理或原始服务器的响应时已超时。</td></tr><tr><td style="text-align:center">HttpVersionNotSupported</td><td style="text-align:left">505</td><td style="text-align:left">指示服务器不支持请求的 HTTP 版本。</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;HttpStatusCode&quot;&gt;&lt;a href=&quot;#HttpStatusCode&quot; class=&quot;headerlink&quot; title=&quot;HttpStatusCode&quot;&gt;&lt;/a&gt;HttpStatusCode&lt;/h1&gt;&lt;figure class=&quot;highlight 
      
    
    </summary>
    
      <category term="前端" scheme="https://wxzhongwang.github.io/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
      <category term="Web" scheme="https://wxzhongwang.github.io/tags/Web/"/>
    
      <category term="前端" scheme="https://wxzhongwang.github.io/tags/%E5%89%8D%E7%AB%AF/"/>
    
  </entry>
  
  <entry>
    <title>优秀的开源项目</title>
    <link href="https://wxzhongwang.github.io/2019/01/08/%E4%BC%98%E7%A7%80%E7%9A%84%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E5%8F%8A%E4%BC%98%E7%A7%80%E6%96%87%E7%AB%A0%E5%9C%B0%E5%9D%80/"/>
    <id>https://wxzhongwang.github.io/2019/01/08/优秀的开源项目及优秀文章地址/</id>
    <published>2019-01-08T06:18:02.000Z</published>
    <updated>2019-01-09T02:01:27.580Z</updated>
    
    <content type="html"><![CDATA[<p>此部分总结平时工作中积累的项目或者见过的优秀开源项目的总结</p><h1 id="优秀的开源项目"><a href="#优秀的开源项目" class="headerlink" title="优秀的开源项目"></a>优秀的开源项目</h1><p>此部分总结平时工作中积累的项目或者见过的优秀开源项目的总结</p><h2 id="前端相关"><a href="#前端相关" class="headerlink" title="前端相关"></a>前端相关</h2><h2 id="NET相关"><a href="#NET相关" class="headerlink" title="NET相关"></a>NET相关</h2><h2 id="NodeJS相关"><a href="#NodeJS相关" class="headerlink" title="NodeJS相关"></a>NodeJS相关</h2><h3 id="NodeJS-中文社区开源"><a href="#NodeJS-中文社区开源" class="headerlink" title="NodeJS 中文社区开源"></a>NodeJS 中文社区开源</h3><p>官网地址:</p><blockquote><p><a href="https://cnodejs.org/" target="_blank" rel="noopener">https://cnodejs.org/</a></p></blockquote><p>项目开源地址：</p><blockquote><p><a href="https://github.com/cnodejs/nodeclub/" target="_blank" rel="noopener">https://github.com/cnodejs/nodeclub/</a></p></blockquote><h2 id="JAVA相关"><a href="#JAVA相关" class="headerlink" title="JAVA相关"></a>JAVA相关</h2><h2 id="数据库相关"><a href="#数据库相关" class="headerlink" title="数据库相关"></a>数据库相关</h2><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h2 id="架构相关"><a href="#架构相关" class="headerlink" title="架构相关"></a>架构相关</h2><h1 id="优秀文章地址"><a href="#优秀文章地址" class="headerlink" title="优秀文章地址"></a>优秀文章地址</h1><p>此部分总结平时工作中积累的优秀文章或者博客</p><h2 id="前端、JAVA、Python"><a href="#前端、JAVA、Python" class="headerlink" title="前端、JAVA、Python"></a>前端、JAVA、Python</h2><blockquote><p><a href="https://www.jqhtml.com/" target="_blank" rel="noopener">https://www.jqhtml.com/</a></p></blockquote><h2 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx:"></a>Nginx:</h2><p>详细文档:</p><blockquote><p><a href="http://tengine.taobao.org/book/index.html" target="_blank" rel="noopener">http://tengine.taobao.org/book/index.html</a></p></blockquote><h2 id="Jekins"><a href="#Jekins" class="headerlink" title="Jekins:"></a>Jekins:</h2><p>教程<br><a href="http://blog.51cto.com/12832314/2140304" target="_blank" rel="noopener">http://blog.51cto.com/12832314/2140304</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;此部分总结平时工作中积累的项目或者见过的优秀开源项目的总结&lt;/p&gt;
&lt;h1 id=&quot;优秀的开源项目&quot;&gt;&lt;a href=&quot;#优秀的开源项目&quot; class=&quot;headerlink&quot; title=&quot;优秀的开源项目&quot;&gt;&lt;/a&gt;优秀的开源项目&lt;/h1&gt;&lt;p&gt;此部分总结平时工作中积累的
      
    
    </summary>
    
      <category term="前端" scheme="https://wxzhongwang.github.io/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
      <category term="Web" scheme="https://wxzhongwang.github.io/tags/Web/"/>
    
  </entry>
  
  <entry>
    <title>大数据</title>
    <link href="https://wxzhongwang.github.io/2019/01/08/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    <id>https://wxzhongwang.github.io/2019/01/08/大数据/</id>
    <published>2019-01-08T06:18:02.000Z</published>
    <updated>2019-01-09T02:01:55.333Z</updated>
    
    <content type="html"><![CDATA[<h1 id="大数据生命周期"><a href="#大数据生命周期" class="headerlink" title="大数据生命周期"></a>大数据生命周期</h1><ul><li>基础设施层，涵盖计算资源、内存与存储和网络互联，具体表现为计算节点、集群、机柜和数据中心。</li><li>数据存储和管理层，包括文件系统、数据库和类似YARN的资源管理系统。</li><li>计算处理层，如hadoop、MapReduce和Spark</li><li>在此之上的各种不同计算范式，如批处理、流处理和图计算等，包括衍生出编程模型的计算模型，如BSP、GAS等</li></ul><blockquote><p>数据分析和可视化基于计算处理层。分析包括简单的查询分析、流分析以及更复杂的分析(如机器学习、图计算等)。查询分析多基于表结构和关系函数，流分析基于数据、事件流以及简单的统计分析，而复杂分析则基于更复杂的数据结构与方法，如图、矩阵、迭代计算和线性代数。一般意义的可视化是对分析结果的展示。但是通过交互式可视化，还可以探索性地提问，使分析获得新的线索，形成迭代的分析和可视化。基于大规模数据的实时交互可视化分析以及在这个过程中引入自动化的因素是目前研究的热点。</p></blockquote><h1 id="大数据技术生态"><a href="#大数据技术生态" class="headerlink" title="大数据技术生态"></a>大数据技术生态</h1><p>大数据的基本处理流程与传统数据处理流程并无太大差异，主要区别在于：由于大数据要处理大量、非结构化的数据，所以在各处理环节中都可以采用并行处理。目前，Hadoop、MapReduce和Spark等分布式处理方式已经成为大数据处理各环节的通用处理方法。</p><h1 id="大数据采集与预处理"><a href="#大数据采集与预处理" class="headerlink" title="大数据采集与预处理"></a>大数据采集与预处理</h1><ul><li>存储层</li><li>预处理层</li><li>采集层</li></ul><p>在大数据的生命周期中，数据采集处于第一个环节。根据MapReduce产生数据的应用系统分类，大数据的采集主要有4种来源：管理信息系统、Web信息系统、物理信息系统、科学实验系统。对于不同的数据集，可能存在不同的结构和模式，如文件、XML树、关系表等，表现为数据的异构性。对多个异构的数据集，需要做进一步集成处理或整合处理，将来自不同数据集的数据收集、整理、清洗、转换后，生成到一个新的数据集，为后续查询和分析处理提供统一的数据视图。针对管理信息系统中异构数据库集成技术、Web信息系统中的实体识别技术和DeepWeb集成技术、传感器网络数据融合技术已经有很多研究工作，取得了较大的进展，已经推出了多种数据清洗和质量控制工具。</p><h1 id="大数据的存储和管理"><a href="#大数据的存储和管理" class="headerlink" title="大数据的存储和管理"></a>大数据的存储和管理</h1><p>按数据类型的不同，大数据的存储和管理采用不同的技术路线，大致可以分为3类。</p><h2 id="第1类"><a href="#第1类" class="headerlink" title="第1类"></a>第1类</h2><p>主要面对的是大规模的结构化数据。针对这类大数据，通常采用新型数据库集群。它们通过列存储或行列混合存储以及粗粒度索引等技术，结合MPP(MassiveParallelProcessing)架构高效的分布式计算模式，实现对PB量级数据的存储和管理。这类集群具有高性能和高扩展性特点，在企业分析类应用领域已获得广泛应用;</p><h2 id="第2类"><a href="#第2类" class="headerlink" title="第2类"></a>第2类</h2><p>主要面对的是半结构化和非结构化数据。应对这类应用场景，基于Hadoop开源体系的系统平台更为擅长。它们通过对Hadoop生态体系的技术扩展和封装，实现对半结构化和非结构化数据的存储和管理;</p><h2 id="第3类"><a href="#第3类" class="headerlink" title="第3类"></a>第3类</h2><p>面对的是结构化和非结构化混合的大数据，因此采用MPP并行数据库集群与Hadoop集群的混合来实现对百PB量级、EB量级数据的存储和管理。一方面，用MPP来管理计算高质量的结构化数据，提供强大的SQL和OLTP型服务;另一方面，用Hadoop实现对半结构化和非结构化数据的处理，以支持诸如内容检索、深度挖掘与综合分析等新型应用。这类混合模式将是大数据存储和管理未来发展的趋势。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;大数据生命周期&quot;&gt;&lt;a href=&quot;#大数据生命周期&quot; class=&quot;headerlink&quot; title=&quot;大数据生命周期&quot;&gt;&lt;/a&gt;大数据生命周期&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;基础设施层，涵盖计算资源、内存与存储和网络互联，具体表现为计算节点、集群、机柜和数据中心
      
    
    </summary>
    
      <category term="大数据" scheme="https://wxzhongwang.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="https://wxzhongwang.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop技术体系</title>
    <link href="https://wxzhongwang.github.io/2019/01/08/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF%EF%BC%88Hadoop%E4%BD%93%E7%B3%BB%EF%BC%89/"/>
    <id>https://wxzhongwang.github.io/2019/01/08/大数据相关技术（Hadoop体系）/</id>
    <published>2019-01-08T06:18:02.000Z</published>
    <updated>2019-01-09T02:02:32.943Z</updated>
    
    <content type="html"><![CDATA[<p>Hadoop 里面包括几个组件<strong>HDFS</strong>、<strong>MapReduce</strong>、<strong>YARN</strong>和<strong>ZooKeeper</strong>等一系列技术，HDFS是存储数据的地方就像我们电脑的硬盘一样文件都存储在这个上面，MapReduce是对数据进行处理计算的，YARN是体现Hadoop平台概念的重要组件，有了它大数据生态体系的其它软件就能在hadoop上运行了，这样能更好的利用HDFS大存储的优势和节省更多的资源比如我们就不用再单独建一个spark的集群了，让它直接跑在现有的hadoop yarn上面就可以了。ZooKeeper本身是一个非常牢靠的记事本，用于记录一些概要信息。Hadoop依靠这个记事本来记录当前哪些节点正在用，哪些已掉线，哪些是备用等，以此来管理机群。</p><h1 id="Hadoop技术体系"><a href="#Hadoop技术体系" class="headerlink" title="Hadoop技术体系"></a>Hadoop技术体系</h1><h2 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h2><p>Hadoop 里面包括几个组件<strong>HDFS</strong>、<strong>MapReduce</strong>、<strong>YARN</strong>和<strong>ZooKeeper</strong>等一系列技术，HDFS是存储数据的地方就像我们电脑的硬盘一样文件都存储在这个上面，MapReduce是对数据进行处理计算的，YARN是体现Hadoop平台概念的重要组件，有了它大数据生态体系的其它软件就能在hadoop上运行了，这样能更好的利用HDFS大存储的优势和节省更多的资源比如我们就不用再单独建一个spark的集群了，让它直接跑在现有的hadoop yarn上面就可以了。ZooKeeper本身是一个非常牢靠的记事本，用于记录一些概要信息。Hadoop依靠这个记事本来记录当前哪些节点正在用，哪些已掉线，哪些是备用等，以此来管理机群。</p><h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><p>Hadoop Distributed File System，Hadoop 分布式文件系统<br>高度容错性的系统，适合部署在廉价的机器上，HDFS能提供高吞吐量的数据访问，适合那些有着超大数据集（large data set）的应用程序。</p><h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><p>Mapreduce是一个计算框架，一个处理分布式海量数据的软件框架及计算集群。</p><p>Map （映射） Reduce (简化)<br>举个例子：假设你的手机通话信息保存在一个HDFS的文件callList.txt中，你想找到你与同事A的所有通话记录并排序。因为HDFS会把callLst.txt分成几块分别存，比如说5块，那么对应的Map过程就是找到这5块所在的5个节点，让它们分别找自己存的那块中关于同事A的通话记录，对应的Reduce过程就是把5个节点过滤后的通话记录合并在一块并按时间排序。MapReduce的计算模型通常把HDFS作为数据来源，很少会用到其它数据来源比如HBase。</p><h2 id="Hbase"><a href="#Hbase" class="headerlink" title="Hbase"></a>Hbase</h2><p>这是Hadoop生态体系中的NOSQL数据库，他的数据是按照key和value的形式存储的并且key是唯一的，所以它能用来做数据的排重，它与MYSQL相比能存储的数据量大很多。所以他常被用于大数据处理完成之后的存储目的地。</p><blockquote><p>HDFS和HBase是依靠外存（即硬盘）的分布式文件存储实现和分布式表存储实现。HDFS是一个分布式的“云存储”文件系统，它会把一个文件分块并分别保存，取用时分别再取出、合并。重要的是，这些分块通常会在3个节点（即集群内的服务器）上各有1个备份，因此即使出现少数节点的失效（如硬盘损坏、掉电等），文件也不会失效。如果说HDFS是文件级别的存储，那HBase则是表级别的存储。HBase是表模型，但比SQL数据库的表要简单的多，没有连接、聚集等功能。HBase的表是物理存储到HDFS的，比如把一个表分成4个HDFS文件并存储。由于HDFS级会做备份，所以HBase级不再备份。MapReduce则是一个计算模型，而不是存储模型；MapReduce通常与HDFS紧密配合。</p></blockquote><h2 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h2><p>Hive 是一种底层封装了Hadoop 的数据仓库处理工具，使用类SQL的HiveQL语言实现数据查询，所有Hive 的数据都存储在Hadoop 兼容的文件系统（如HDFS）中。Hive在加载数据过程中不会对数据进行任何的修改，只是将数据移动到HDFS中Hive设定的目录下，++因此，Hive不支持对数据的改写和添加，所有的数据都是在加载的时候确定的++。对于会SQL语法的来说就是神器，它能让你处理大数据变的很简单，不会再费劲的编写MapReduce程序。</p><h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><p>它是用来弥补基于MapReduce处理数据速度上的缺点，它的特点是把数据装载到内存中计算而不是去读慢的要死进化还特别慢的硬盘。特别适合做迭代运算，所以算法流们特别稀饭它。它是用scala编写的。Java语言或者Scala都可以操作它，因为它们都是用JVM的。</p><h1 id="其他相关技术"><a href="#其他相关技术" class="headerlink" title="其他相关技术"></a>其他相关技术</h1><h2 id="Sqoop"><a href="#Sqoop" class="headerlink" title="Sqoop"></a>Sqoop</h2><p>这个是用于把Mysql里的数据导入到Hadoop里的。当然你也可以不用这个，直接把Mysql数据表导出成文件再放到HDFS上也是一样的，当然生产环境中使用要注意Mysql的压力。</p><h2 id="Flume"><a href="#Flume" class="headerlink" title="Flume"></a>Flume</h2><p> apache Flume 是一个从可以收集例如日志，事件等数据资源，并将这些数量庞大的数据从各项数据资源中集中起来存储的工具/服务，或者数集中机制。flume具有高可用，分布式，配置工具，其设计的原理也是基于数据流，如日志数据从各种网站服务器上汇集起来存储到HDFS，HBase等集中存储器中。</p><h3 id="一般实时系统，所选用组件如下"><a href="#一般实时系统，所选用组件如下" class="headerlink" title="一般实时系统，所选用组件如下"></a>一般实时系统，所选用组件如下</h3><ul><li>数据采集 ：负责从各节点上实时采集数据，选用Flume来实现  </li><li>数据接入 ：由于采集数据的速度和数据处理的速度不一定同步，因此添加一个消息中间件来作为缓冲，选用apache的kafka  </li><li>流式计算 ：对采集到的数据进行实时分析，选用apache的storm  </li><li>数据输出 ：对分析后的结果持久化，暂定用mysql，另一方面是模块化之后，假如当Storm挂掉了之后，数据采集和数据接入还是继续在跑着，数据不会丢失，storm起来之后可以继续进行流式计算； </li></ul><h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><p>Kafka的整体架构非常简单，是显式分布式架构，producer、broker（kafka）和consumer都可以有多个。Producer，consumer实现Kafka注册的接口，数据从producer发送到broker，broker承担一个中间缓存和分发的作用。broker分发注册到系统中的consumer。broker的作用类似于缓存，即活跃的数据和离线处理系统之间的缓存。客户端和服务器端的通信，是基于简单，高性能，且与编程语言无关的TCP协议。</p><p>Kafka是一种分布式的、基于发布/订阅的消息系统。在流式计算中，Kafka一般用来缓存数据，Storm通过消费Kafka的数据进行计算（KAFKA+STORM+REDIS）。</p><p>特点：</p><ul><li>消息持久化：通过O(1)的磁盘数据结构提供数据的持久化</li><li>高吞吐量：每秒百万级的消息读写</li><li>分布式：扩展能力强</li><li>多客户端支持：java、php、python、c++ ……</li><li>实时性：生产者生产的message立即被消费者可见</li><li>Kafka是一个分布式消息队列：生产者、消费者的功能。它提供了类似于JMS的特性，但是在设计实   现上完全不同，此外它并不是JMS规范的实现。</li><li>Kafka对消息保存时根据Topic进行归类，发送消息者称为Producer,消息接受者称为Consumer</li><li>无论是kafka集群，还是producer和consumer都依赖于zookeeper集群保存一些meta信息，来保证系统可用性</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Hadoop 里面包括几个组件&lt;strong&gt;HDFS&lt;/strong&gt;、&lt;strong&gt;MapReduce&lt;/strong&gt;、&lt;strong&gt;YARN&lt;/strong&gt;和&lt;strong&gt;ZooKeeper&lt;/strong&gt;等一系列技术，HDFS是存储数据的地方就像我们电脑
      
    
    </summary>
    
      <category term="大数据" scheme="https://wxzhongwang.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://wxzhongwang.github.io/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>消息队列</title>
    <link href="https://wxzhongwang.github.io/2019/01/08/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    <id>https://wxzhongwang.github.io/2019/01/08/消息队列/</id>
    <published>2019-01-08T06:18:02.000Z</published>
    <updated>2019-01-09T02:03:22.149Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、消息队列的基本概念"><a href="#一、消息队列的基本概念" class="headerlink" title="一、消息队列的基本概念"></a>一、消息队列的基本概念</h1><h2 id="1-1-Broker"><a href="#1-1-Broker" class="headerlink" title="1.1 Broker"></a>1.1 Broker</h2><p>==Broker== 的概念来自与Apache ActiveMQ，通俗的讲就是消息队列服务器。</p><h2 id="1-2-消息生产者和消费者"><a href="#1-2-消息生产者和消费者" class="headerlink" title="1.2 消息生产者和消费者"></a>1.2 消息生产者和消费者</h2><ul><li>消息生产者 ==Producer==：发送消息到消息队列。</li><li>消息消费者 ==Consumer==：从消息队列接收消息。</li></ul><h2 id="1-3-消息模型"><a href="#1-3-消息模型" class="headerlink" title="1.3 消息模型"></a>1.3 消息模型</h2><h3 id="点对点消息队列模型"><a href="#点对点消息队列模型" class="headerlink" title="点对点消息队列模型"></a>点对点消息队列模型</h3><p>消息生产者向一个特定的队列发送消息，消息消费者从该队列中接收消息。消息的生产者和消费者可以不同时处于运行状态。每一个成功处理的消息都由消息消费者签收确认（Acknowledge）。</p><h3 id="发布订阅消息模型-Topic"><a href="#发布订阅消息模型-Topic" class="headerlink" title="发布订阅消息模型-Topic"></a>发布订阅消息模型-Topic</h3><p>发布订阅消息模型中，支持向一个特定的主题Topic发布消息，0个或多个订阅者接收来自这个消息主题的消息。在这种模型下，发布者和订阅者彼此不知道对方。实际操作过程中，必须先订阅，再发送消息，而后接收订阅的消息，这个顺序必须保证。 </p><h2 id="1-4-消息顺序性保证"><a href="#1-4-消息顺序性保证" class="headerlink" title="1.4 消息顺序性保证"></a>1.4 消息顺序性保证</h2><p>基于Queue消息模型，利用FIFO先进先出的特性，可以保证消息的顺序性。</p><h2 id="1-5-消息的ACK确认机制"><a href="#1-5-消息的ACK确认机制" class="headerlink" title="1.5 消息的ACK确认机制"></a>1.5 消息的ACK确认机制</h2><p>即消息的Ackownledge确认机制：<br>为了保证消息不丢失，消息队列提供了消息Acknowledge机制，即ACK机制，当Consumer确认消息已经消费处理，发送一个ACK给消息队列，此时消息队列便可以删除这个消息了。如果Consumer宕机/关闭，没有发送ACK，消息队列将认为这个消息没有被处理，会将这个消息重新发送给其他的Consumer重新消费处理。</p><h2 id="1-6-消息的持久化"><a href="#1-6-消息的持久化" class="headerlink" title="1.6 消息的持久化"></a>1.6 消息的持久化</h2><p>消息的持久化，对于一些关键的核心业务来说是非常重要的，启用消息持久化后，消息队列宕机重启后，消息可以从持久化存储恢复，消息不丢失，可以继续消费处理。</p><h2 id="1-7-消息的同步和异步收发"><a href="#1-7-消息的同步和异步收发" class="headerlink" title="1.7 消息的同步和异步收发"></a>1.7 消息的同步和异步收发</h2><h3 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h3><p>消息的收发支持同步收发的方式<br>同步收发场景下，消息生产者和消费者双向应答模式，例如：张三写封信送到邮局中转站，然后李四从中转站获得信，然后在写一份回执信，放到中转站，然后张三去取，当然张三写信的时候就得写明回信地址。<br>消息的接收如果以同步的方式(Pull)进行接收，如果队列中为空，此时接收将处于同步阻塞状态，会一直等待，直到消息的到达。</p><h3 id="异步"><a href="#异步" class="headerlink" title="异步"></a>异步</h3><p>消息的收发同样支持异步方式：异步发送消息，不需要等待消息队列的接收确认。<br>异步接收消息，以Push的方式触发消息消费者接收消息。</p><h2 id="1-8-消息的事务支持"><a href="#1-8-消息的事务支持" class="headerlink" title="1.8 消息的事务支持"></a>1.8 消息的事务支持</h2><p>消息的收发处理支持事务，例如：在任务中心场景中，一次处理可能涉及多个消息的接收、处理，这处于同一个事务范围内，如果一个消息处理失败，事务回滚，消息重新回到队列中。</p><h1 id="二、JMS消费服务"><a href="#二、JMS消费服务" class="headerlink" title="二、JMS消费服务"></a>二、JMS消费服务</h1><p>Java消息服务（Java Message Service，JMS）应用程序接口是一个Java平台中关于面向消息中间件（MOM）的API，用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。 点对点与发布订阅最初是由JMS定义的。这两种模式主要区别或解决的问题就是发送到队列的消息能否重复消费(多订阅) 。</p><p>JMS规范目前支持两种消息模型：</p><ol><li>点对点（point to point， queue）</li><li>发布/订阅（publish/subscribe，topic）</li></ol><h2 id="2-1-点对点：Queue，不可重复消费"><a href="#2-1-点对点：Queue，不可重复消费" class="headerlink" title="2.1 点对点：Queue，不可重复消费"></a>2.1 点对点：Queue，不可重复消费</h2><p>消息生产者生产消息发送到queue中，然后消息消费者从queue中取出并且消费消息。<br>消息被消费以后，queue中不再有存储，所以消息消费者不可能消费到已经被消费的消息。<br>Queue支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。 </p><p>P2P模式包含三个角色：</p><ul><li>消息队列（Queue）</li><li>发送者(Sender)</li><li>接收者(Receiver)</li></ul><p>每个消息都被发送到一个特定的队列，接收者从队列中获取消息。队列保留着消息，<br>直到他们被消费或超时。</p><h2 id="2-2-发布-订阅：Topic，可以重复消费"><a href="#2-2-发布-订阅：Topic，可以重复消费" class="headerlink" title="2.2 发布/订阅：Topic，可以重复消费"></a>2.2 发布/订阅：Topic，可以重复消费</h2><p>消息生产者（发布）将消息发布到topic中，同时有多个消息消费者（订阅）消费该消息。<br>和点对点方式不同，发布到topic的消息会被所有订阅者消费。 </p><p>支持订阅组的发布订阅模式：<br>发布订阅模式下，当发布者消息量很大时，显然单个订阅者的处理能力是不足的。实际上现实场景中是多个订阅者节点组成一个订阅组负载均衡消费topic消息即分组订阅，这样订阅者很容易实现消费能力线性扩展。可以看成是一个topic下有多个Queue，每个Queue是点对点的方式，Queue之间是发布订阅方式。 </p><h2 id="2-3-区别"><a href="#2-3-区别" class="headerlink" title="2.3 区别"></a>2.3 区别</h2><h3 id="点对点模式"><a href="#点对点模式" class="headerlink" title="点对点模式"></a>点对点模式</h3><p>生产者发送一条消息到queue，一个queue可以有很多消费者，但是一个消息只能被一个消费者接受，当没有消费者可用时，这个消息会被保存直到有一个可用的消费者，所以Queue实现了一个可靠的负载均衡。</p><h3 id="发布订阅模式"><a href="#发布订阅模式" class="headerlink" title="发布订阅模式"></a>发布订阅模式</h3><p>发布者发送到topic的消息，只有订阅了topic的订阅者才会收到消息。topic实现了发布和订阅，当你发布一个消息，所有订阅这个topic的服务都能得到这个消息，所以从1到N个订阅者都能得到这个消息的拷贝。</p><h1 id="三、流行模型对比"><a href="#三、流行模型对比" class="headerlink" title="三、流行模型对比"></a>三、流行模型对比</h1><p>传统企业型消息队列ActiveMQ遵循了JMS规范，实现了点对点和发布订阅模型，但其他流行的消息队列RabbitMQ、Kafka并没有遵循JMS规范。</p><h2 id="3-1-RabbitMQ"><a href="#3-1-RabbitMQ" class="headerlink" title="3.1 RabbitMQ"></a>3.1 RabbitMQ</h2><p>RabbitMQ实现了AQMP协议，AQMP协议定义了消息路由规则和方式。生产端通过路由规则发送消息到不同queue，消费端根据queue名称消费消息。RabbitMQ既支持内存队列也支持持久化队列，消费端为推模型，消费状态和订阅关系由服务端负责维护，消息消费完后立即删除，不保留历史消息。</p><h3 id="点对点"><a href="#点对点" class="headerlink" title="点对点"></a>点对点</h3><p>生产端发送一条消息通过路由投递到Queue，只有一个消费者能消费到。 </p><h3 id="多订阅"><a href="#多订阅" class="headerlink" title="多订阅"></a>多订阅</h3><p>当RabbitMQ需要支持多订阅时，发布者发送的消息通过路由同时写到多个Queue，不同订阅组消费不同的Queue。所以支持多订阅时，消息会多个拷贝。 </p><h2 id="3-2-Kafka"><a href="#3-2-Kafka" class="headerlink" title="3.2 Kafka"></a>3.2 Kafka</h2><p>Kafka只支持消息持久化，消费端为拉模型，消费状态和订阅关系由客户端端负责维护，消息消费完后不会立即删除，会保留历史消息。因此支持多订阅时，消息只会存储一份就可以了。但是可能产生重复消费的情况。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一、消息队列的基本概念&quot;&gt;&lt;a href=&quot;#一、消息队列的基本概念&quot; class=&quot;headerlink&quot; title=&quot;一、消息队列的基本概念&quot;&gt;&lt;/a&gt;一、消息队列的基本概念&lt;/h1&gt;&lt;h2 id=&quot;1-1-Broker&quot;&gt;&lt;a href=&quot;#1-1-Bro
      
    
    </summary>
    
      <category term="消息队列" scheme="https://wxzhongwang.github.io/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
      <category term="MessageQueue" scheme="https://wxzhongwang.github.io/tags/MessageQueue/"/>
    
  </entry>
  
  <entry>
    <title>Git使用中的问题</title>
    <link href="https://wxzhongwang.github.io/2019/01/08/Git%E4%BD%BF%E7%94%A8%E4%B8%AD%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>https://wxzhongwang.github.io/2019/01/08/Git使用中的问题/</id>
    <published>2019-01-08T06:18:02.000Z</published>
    <updated>2019-01-08T06:29:58.885Z</updated>
    
    <content type="html"><![CDATA[<p>git push失败 fatal: Could not read from remote repository</p><h2 id="阐述问题"><a href="#阐述问题" class="headerlink" title="阐述问题"></a>阐述问题</h2><p>git push失败 fatal: Could not read from remote repository. 因为仓库地址不对。更改地址就可以push了。</p><h3 id="问题原因"><a href="#问题原因" class="headerlink" title="问题原因"></a>问题原因</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git remote -v</span><br><span class="line">$ git remote <span class="built_in">set</span>-url origin XXX</span><br></pre></td></tr></table></figure><h2 id="服务器上的-Git-生成-SSH-公钥"><a href="#服务器上的-Git-生成-SSH-公钥" class="headerlink" title="服务器上的 Git - 生成 SSH 公钥"></a>服务器上的 Git - 生成 SSH 公钥</h2><h3 id="生成-SSH-公钥"><a href="#生成-SSH-公钥" class="headerlink" title="生成 SSH 公钥"></a>生成 SSH 公钥</h3><p>大多数 Git 服务器都会选择使用 SSH 公钥来进行授权。系统中的每个用户都必须提供一个公钥用于授权，没有的话就要生成一个。生成公钥的过程在所有操作系统上都差不多。首先先确认一下是否已经有一个公钥了。SSH 公钥默认储存在账户的主目录下的 ~/.ssh 目录。<br>若想在github中使用的话需要将公钥复制到github&gt;setting&gt;SSH and GPG keys中添加ssh keys。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">生成钥匙</span><br><span class="line">$ ssh-keygen</span><br><span class="line">查看公钥</span><br><span class="line"><span class="variable">$cat</span> ~/.ssh/id_rsa.pub</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;git push失败 fatal: Could not read from remote repository&lt;/p&gt;
&lt;h2 id=&quot;阐述问题&quot;&gt;&lt;a href=&quot;#阐述问题&quot; class=&quot;headerlink&quot; title=&quot;阐述问题&quot;&gt;&lt;/a&gt;阐述问题&lt;/h2&gt;&lt;p
      
    
    </summary>
    
      <category term="版本控制工具" scheme="https://wxzhongwang.github.io/categories/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="Git" scheme="https://wxzhongwang.github.io/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>你好，世界</title>
    <link href="https://wxzhongwang.github.io/2018/08/31/hello-world/"/>
    <id>https://wxzhongwang.github.io/2018/08/31/hello-world/</id>
    <published>2018-08-31T09:54:54.000Z</published>
    <updated>2019-01-08T06:12:54.428Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
      <category term="博客搭建" scheme="https://wxzhongwang.github.io/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="前端" scheme="https://wxzhongwang.github.io/tags/%E5%89%8D%E7%AB%AF/"/>
    
      <category term="博客系统" scheme="https://wxzhongwang.github.io/tags/%E5%8D%9A%E5%AE%A2%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
</feed>
